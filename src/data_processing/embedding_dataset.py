import torch
from torch.utils.data import Dataset
import json
import os
import pandas as pd
import numpy as np

class MELDEmbeddingDataset(Dataset):
    """
    Custom PyTorch Dataset for loading the pre-calculated audio and text embeddings
    generated by the `create_embeddings.py` script.
    Ensures every CSV row is represented (with zero-vector fallback if needed).
    """
    def __init__(self, project_root, data_type='train'):
        """
        Initializes the dataset by locating the processed JSON files and mapping labels.
        """
        self.project_root = project_root
        self.data_type = data_type
        self.json_dir = os.path.join(self.project_root, 'data', 'processed', 'json_embeddings')
        raw_data_dir = os.path.join(self.project_root, 'data', 'raw')

        if self.data_type == 'train':
            csv_path = os.path.join(raw_data_dir, 'train_sent_emo.csv')
        elif self.data_type == 'dev':
            csv_path = os.path.join(raw_data_dir, 'dev_sent_emo.csv')
        else:  # test
            csv_path = os.path.join(raw_data_dir, 'test_sent_emo.csv')

        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"CSV file not found at {csv_path}")

        self.df = pd.read_csv(csv_path)

        # Map labels
        self.sentiment_mapping = {'positive': 0, 'negative': 1, 'neutral': 2}
        self.emotion_mapping = {
            'neutral': 0, 'joy': 1, 'sadness': 2,
            'fear': 3, 'anger': 4, 'surprise': 5, 'disgust': 6
        }

        # Inverse mappings (id → label) for prediction output
        self.sentiment_mapping_inv = {v: k for k, v in self.sentiment_mapping.items()}
        self.emotion_mapping_inv = {v: k for k, v in self.emotion_mapping.items()}

        print(f"Loaded {len(self.df)} rows from {os.path.basename(csv_path)}")
        print(f"Looking for JSONs in {self.json_dir}")

    def __len__(self):
        """Returns the total number of samples in the dataset (same as CSV)."""
        return len(self.df)

    def __getitem__(self, idx):
        """
        Fetches the sample at the given index, loads its data (or creates fallback).
        """
        row = self.df.iloc[idx]
        dialogue_id = row['Dialogue_ID']
        utterance_id = row['Utterance_ID']
        json_filename = f"dia{dialogue_id}_utt{utterance_id}.json"
        json_path = os.path.join(self.json_dir, json_filename)

        if not os.path.exists(json_path):
            print(f"⚠️ WARNING: JSON not found for {json_filename}. Using placeholder embeddings.")
            audio_embedding = np.zeros(768, dtype=np.float32)
            text_embedding = np.zeros(768, dtype=np.float32)
            sentiment = row['Sentiment']
            emotion = row['Emotion']
        else:
            try:
                with open(json_path, 'r') as f:
                    data = json.load(f)

                audio_embedding = np.array(data.get('audio_embedding', [0.0] * 768), dtype=np.float32)
                text_embedding = np.array(data.get('text_embedding', [0.0] * 768), dtype=np.float32)
                sentiment = data.get('sentiment', row['Sentiment'])
                emotion = data.get('emotion', row['Emotion'])

                # Detect placeholder vectors
                if not np.any(audio_embedding):
                    print(f"⚠️ Placeholder audio embedding in {json_filename}")
                if not np.any(text_embedding):
                    print(f"⚠️ Placeholder text embedding in {json_filename}")

            except (json.JSONDecodeError, KeyError, TypeError) as e:
                print(f"⚠️ ERROR reading {json_filename}. Using placeholders. Error: {e}")
                audio_embedding = np.zeros(768, dtype=np.float32)
                text_embedding = np.zeros(768, dtype=np.float32)
                sentiment = row['Sentiment']
                emotion = row['Emotion']

        sample = {
            'audio_embedding': torch.tensor(audio_embedding, dtype=torch.float32),
            'text_embedding': torch.tensor(text_embedding, dtype=torch.float32),
            'sentiment_label': torch.tensor(self.sentiment_mapping.get(sentiment, 2), dtype=torch.long),
            'emotion_label': torch.tensor(self.emotion_mapping.get(emotion, 0), dtype=torch.long),
            'dialogue_id': dialogue_id,
            'utterance_id': utterance_id
        }
        return sample
